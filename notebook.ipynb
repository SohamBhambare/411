{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3351, 21)\n",
      "(3343, 21)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./airline_delay.csv\")\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>carrier</th>\n",
       "      <th>carrier_name</th>\n",
       "      <th>airport</th>\n",
       "      <th>airport_name</th>\n",
       "      <th>arr_flights</th>\n",
       "      <th>arr_del15</th>\n",
       "      <th>carrier_ct</th>\n",
       "      <th>weather_ct</th>\n",
       "      <th>...</th>\n",
       "      <th>security_ct</th>\n",
       "      <th>late_aircraft_ct</th>\n",
       "      <th>arr_cancelled</th>\n",
       "      <th>arr_diverted</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9E</td>\n",
       "      <td>Endeavor Air Inc.</td>\n",
       "      <td>ABE</td>\n",
       "      <td>Allentown/Bethlehem/Easton, PA: Lehigh Valley ...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9E</td>\n",
       "      <td>Endeavor Air Inc.</td>\n",
       "      <td>ABY</td>\n",
       "      <td>Albany, GA: Southwest Georgia Regional</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9E</td>\n",
       "      <td>Endeavor Air Inc.</td>\n",
       "      <td>AEX</td>\n",
       "      <td>Alexandria, LA: Alexandria International</td>\n",
       "      <td>88.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9E</td>\n",
       "      <td>Endeavor Air Inc.</td>\n",
       "      <td>AGS</td>\n",
       "      <td>Augusta, GA: Augusta Regional at Bush Field</td>\n",
       "      <td>184.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9E</td>\n",
       "      <td>Endeavor Air Inc.</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Albany, NY: Albany International</td>\n",
       "      <td>76.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9E</td>\n",
       "      <td>Endeavor Air Inc.</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta, GA: Hartsfield-Jackson Atlanta Intern...</td>\n",
       "      <td>5985.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>142.89</td>\n",
       "      <td>11.96</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127.79</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30756.0</td>\n",
       "      <td>16390.0</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>5060.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9E</td>\n",
       "      <td>Endeavor Air Inc.</td>\n",
       "      <td>ATW</td>\n",
       "      <td>Appleton, WI: Appleton International</td>\n",
       "      <td>142.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9E</td>\n",
       "      <td>Endeavor Air Inc.</td>\n",
       "      <td>AVL</td>\n",
       "      <td>Asheville, NC: Asheville Regional</td>\n",
       "      <td>147.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9E</td>\n",
       "      <td>Endeavor Air Inc.</td>\n",
       "      <td>AZO</td>\n",
       "      <td>Kalamazoo, MI: Kalamazoo/Battle Creek Internat...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.24</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9E</td>\n",
       "      <td>Endeavor Air Inc.</td>\n",
       "      <td>BDL</td>\n",
       "      <td>Hartford, CT: Bradley International</td>\n",
       "      <td>150.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month carrier       carrier_name airport  \\\n",
       "0  2020     12      9E  Endeavor Air Inc.     ABE   \n",
       "1  2020     12      9E  Endeavor Air Inc.     ABY   \n",
       "2  2020     12      9E  Endeavor Air Inc.     AEX   \n",
       "3  2020     12      9E  Endeavor Air Inc.     AGS   \n",
       "4  2020     12      9E  Endeavor Air Inc.     ALB   \n",
       "5  2020     12      9E  Endeavor Air Inc.     ATL   \n",
       "6  2020     12      9E  Endeavor Air Inc.     ATW   \n",
       "7  2020     12      9E  Endeavor Air Inc.     AVL   \n",
       "8  2020     12      9E  Endeavor Air Inc.     AZO   \n",
       "9  2020     12      9E  Endeavor Air Inc.     BDL   \n",
       "\n",
       "                                        airport_name  arr_flights  arr_del15  \\\n",
       "0  Allentown/Bethlehem/Easton, PA: Lehigh Valley ...         44.0        3.0   \n",
       "1             Albany, GA: Southwest Georgia Regional         90.0        1.0   \n",
       "2           Alexandria, LA: Alexandria International         88.0        8.0   \n",
       "3        Augusta, GA: Augusta Regional at Bush Field        184.0        9.0   \n",
       "4                   Albany, NY: Albany International         76.0       11.0   \n",
       "5  Atlanta, GA: Hartsfield-Jackson Atlanta Intern...       5985.0      445.0   \n",
       "6               Appleton, WI: Appleton International        142.0       14.0   \n",
       "7                  Asheville, NC: Asheville Regional        147.0       10.0   \n",
       "8  Kalamazoo, MI: Kalamazoo/Battle Creek Internat...         84.0       14.0   \n",
       "9                Hartford, CT: Bradley International        150.0       19.0   \n",
       "\n",
       "   carrier_ct  weather_ct  ...  security_ct  late_aircraft_ct  arr_cancelled  \\\n",
       "0        1.63        0.00  ...          0.0              1.25            0.0   \n",
       "1        0.96        0.00  ...          0.0              0.00            0.0   \n",
       "2        5.75        0.00  ...          0.0              0.65            0.0   \n",
       "3        4.17        0.00  ...          0.0              3.00            0.0   \n",
       "4        4.78        0.00  ...          0.0              1.00            1.0   \n",
       "5      142.89       11.96  ...          1.0            127.79            5.0   \n",
       "6        5.36        0.00  ...          0.0              0.94            1.0   \n",
       "7        6.04        1.00  ...          0.0              1.96            0.0   \n",
       "8        6.24        0.96  ...          0.0              0.00            1.0   \n",
       "9        5.70        0.00  ...          0.0              1.23            3.0   \n",
       "\n",
       "   arr_diverted  arr_delay  carrier_delay  weather_delay  nas_delay  \\\n",
       "0           1.0       89.0           56.0            0.0        3.0   \n",
       "1           0.0       23.0           22.0            0.0        1.0   \n",
       "2           1.0      338.0          265.0            0.0       45.0   \n",
       "3           0.0      508.0          192.0            0.0       92.0   \n",
       "4           0.0      692.0          398.0            0.0      178.0   \n",
       "5           0.0    30756.0        16390.0         1509.0     5060.0   \n",
       "6           0.0      436.0          162.0            0.0      182.0   \n",
       "7           1.0     1070.0          838.0          141.0       24.0   \n",
       "8           1.0     2006.0         1164.0          619.0      223.0   \n",
       "9           0.0      846.0          423.0            0.0      389.0   \n",
       "\n",
       "   security_delay  late_aircraft_delay  \n",
       "0             0.0                 30.0  \n",
       "1             0.0                  0.0  \n",
       "2             0.0                 28.0  \n",
       "3             0.0                224.0  \n",
       "4             0.0                116.0  \n",
       "5            16.0               7781.0  \n",
       "6             0.0                 92.0  \n",
       "7             0.0                 67.0  \n",
       "8             0.0                  0.0  \n",
       "9             0.0                 34.0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./airline_delay.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude leaky variables -- we'll only keep what we think could reasonably be known before flight time\n",
    "features = ['year', 'month', 'carrier', 'airport', 'arr_flights']\n",
    "features = pd.get_dummies(df[features])\n",
    "labels = df['arr_del15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>arr_flights</th>\n",
       "      <th>carrier_9E</th>\n",
       "      <th>carrier_AA</th>\n",
       "      <th>carrier_AS</th>\n",
       "      <th>carrier_B6</th>\n",
       "      <th>carrier_DL</th>\n",
       "      <th>carrier_EV</th>\n",
       "      <th>carrier_F9</th>\n",
       "      <th>...</th>\n",
       "      <th>airport_USA</th>\n",
       "      <th>airport_VCT</th>\n",
       "      <th>airport_VEL</th>\n",
       "      <th>airport_VLD</th>\n",
       "      <th>airport_VPS</th>\n",
       "      <th>airport_WRG</th>\n",
       "      <th>airport_XNA</th>\n",
       "      <th>airport_XWA</th>\n",
       "      <th>airport_YAK</th>\n",
       "      <th>airport_YUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>90.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>88.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>184.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>76.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 380 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  arr_flights  carrier_9E  carrier_AA  carrier_AS  carrier_B6  \\\n",
       "0  2020     12         44.0        True       False       False       False   \n",
       "1  2020     12         90.0        True       False       False       False   \n",
       "2  2020     12         88.0        True       False       False       False   \n",
       "3  2020     12        184.0        True       False       False       False   \n",
       "4  2020     12         76.0        True       False       False       False   \n",
       "\n",
       "   carrier_DL  carrier_EV  carrier_F9  ...  airport_USA  airport_VCT  \\\n",
       "0       False       False       False  ...        False        False   \n",
       "1       False       False       False  ...        False        False   \n",
       "2       False       False       False  ...        False        False   \n",
       "3       False       False       False  ...        False        False   \n",
       "4       False       False       False  ...        False        False   \n",
       "\n",
       "   airport_VEL  airport_VLD  airport_VPS  airport_WRG  airport_XNA  \\\n",
       "0        False        False        False        False        False   \n",
       "1        False        False        False        False        False   \n",
       "2        False        False        False        False        False   \n",
       "3        False        False        False        False        False   \n",
       "4        False        False        False        False        False   \n",
       "\n",
       "   airport_XWA  airport_YAK  airport_YUM  \n",
       "0        False        False        False  \n",
       "1        False        False        False  \n",
       "2        False        False        False  \n",
       "3        False        False        False  \n",
       "4        False        False        False  \n",
       "\n",
       "[5 rows x 380 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PyTorch Dataset\n",
    "class DelayDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.features.iloc[idx].values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels.iloc[idx], dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Datasets and DataLoaders\n",
    "train_dataset = DelayDataset(X_train, y_train)\n",
    "val_dataset = DelayDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel(input_size=features.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Define Loss and Optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with Validation\n",
    "epochs = 100\n",
    "mlp_train_losses, mlp_val_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Training Loss: 27202.65 | Validation Loss: 5565.71\n",
      "Epoch 2 | Training Loss: 16020.61 | Validation Loss: 4822.49\n",
      "Epoch 3 | Training Loss: 9782.28 | Validation Loss: 4718.88\n",
      "Epoch 4 | Training Loss: 6437.92 | Validation Loss: 4364.22\n",
      "Epoch 5 | Training Loss: 3974.36 | Validation Loss: 2601.00\n",
      "Epoch 6 | Training Loss: 2958.98 | Validation Loss: 2039.73\n",
      "Epoch 7 | Training Loss: 2410.44 | Validation Loss: 2056.11\n",
      "Epoch 8 | Training Loss: 2113.35 | Validation Loss: 1789.00\n",
      "Epoch 9 | Training Loss: 1874.67 | Validation Loss: 1415.81\n",
      "Epoch 10 | Training Loss: 1777.91 | Validation Loss: 1735.21\n",
      "Epoch 11 | Training Loss: 1664.94 | Validation Loss: 1494.51\n",
      "Epoch 12 | Training Loss: 1585.74 | Validation Loss: 1405.90\n",
      "Epoch 13 | Training Loss: 1472.82 | Validation Loss: 1195.81\n",
      "Epoch 14 | Training Loss: 1343.64 | Validation Loss: 1499.68\n",
      "Epoch 15 | Training Loss: 1246.09 | Validation Loss: 1235.66\n",
      "Epoch 16 | Training Loss: 1083.21 | Validation Loss: 1602.04\n",
      "Epoch 17 | Training Loss: 1074.29 | Validation Loss: 1305.43\n",
      "Epoch 18 | Training Loss: 971.50 | Validation Loss: 1418.91\n",
      "Epoch 19 | Training Loss: 930.87 | Validation Loss: 1126.05\n",
      "Epoch 20 | Training Loss: 839.99 | Validation Loss: 1109.30\n",
      "Epoch 21 | Training Loss: 764.95 | Validation Loss: 996.92\n",
      "Epoch 22 | Training Loss: 691.14 | Validation Loss: 1377.63\n",
      "Epoch 23 | Training Loss: 588.87 | Validation Loss: 1014.57\n",
      "Epoch 24 | Training Loss: 625.94 | Validation Loss: 874.44\n",
      "Epoch 25 | Training Loss: 510.22 | Validation Loss: 952.21\n",
      "Epoch 26 | Training Loss: 482.28 | Validation Loss: 1026.30\n",
      "Epoch 27 | Training Loss: 473.63 | Validation Loss: 956.43\n",
      "Epoch 28 | Training Loss: 482.18 | Validation Loss: 925.75\n",
      "Epoch 29 | Training Loss: 362.15 | Validation Loss: 897.48\n",
      "Epoch 30 | Training Loss: 352.35 | Validation Loss: 901.95\n",
      "Epoch 31 | Training Loss: 297.39 | Validation Loss: 871.29\n",
      "Epoch 32 | Training Loss: 323.16 | Validation Loss: 966.98\n",
      "Epoch 33 | Training Loss: 303.48 | Validation Loss: 806.05\n",
      "Epoch 34 | Training Loss: 324.88 | Validation Loss: 744.57\n",
      "Epoch 35 | Training Loss: 546.12 | Validation Loss: 864.53\n",
      "Epoch 36 | Training Loss: 312.41 | Validation Loss: 787.68\n",
      "Epoch 37 | Training Loss: 213.39 | Validation Loss: 754.69\n",
      "Epoch 38 | Training Loss: 223.59 | Validation Loss: 744.74\n",
      "Epoch 39 | Training Loss: 185.36 | Validation Loss: 781.87\n",
      "Epoch 40 | Training Loss: 157.26 | Validation Loss: 733.69\n",
      "Epoch 41 | Training Loss: 152.18 | Validation Loss: 763.94\n",
      "Epoch 42 | Training Loss: 234.74 | Validation Loss: 707.42\n",
      "Epoch 43 | Training Loss: 234.40 | Validation Loss: 931.61\n",
      "Epoch 44 | Training Loss: 179.39 | Validation Loss: 784.35\n",
      "Epoch 45 | Training Loss: 201.47 | Validation Loss: 737.49\n",
      "Epoch 46 | Training Loss: 425.00 | Validation Loss: 733.60\n",
      "Epoch 47 | Training Loss: 180.27 | Validation Loss: 726.59\n",
      "Epoch 48 | Training Loss: 127.20 | Validation Loss: 700.19\n",
      "Epoch 49 | Training Loss: 116.52 | Validation Loss: 712.36\n",
      "Epoch 50 | Training Loss: 104.67 | Validation Loss: 797.53\n",
      "Epoch 51 | Training Loss: 98.46 | Validation Loss: 729.93\n",
      "Epoch 52 | Training Loss: 84.97 | Validation Loss: 683.15\n",
      "Epoch 53 | Training Loss: 129.53 | Validation Loss: 756.81\n",
      "Epoch 54 | Training Loss: 195.45 | Validation Loss: 847.09\n",
      "Epoch 55 | Training Loss: 210.64 | Validation Loss: 681.79\n",
      "Epoch 56 | Training Loss: 143.62 | Validation Loss: 797.25\n",
      "Epoch 57 | Training Loss: 134.23 | Validation Loss: 736.14\n",
      "Epoch 58 | Training Loss: 117.81 | Validation Loss: 828.90\n",
      "Epoch 59 | Training Loss: 150.68 | Validation Loss: 707.92\n",
      "Epoch 60 | Training Loss: 157.34 | Validation Loss: 880.93\n",
      "Epoch 61 | Training Loss: 179.65 | Validation Loss: 870.77\n",
      "Epoch 62 | Training Loss: 158.34 | Validation Loss: 752.49\n",
      "Epoch 63 | Training Loss: 111.79 | Validation Loss: 690.76\n",
      "Epoch 64 | Training Loss: 99.23 | Validation Loss: 716.49\n",
      "Epoch 65 | Training Loss: 77.23 | Validation Loss: 771.02\n",
      "Epoch 66 | Training Loss: 73.21 | Validation Loss: 766.68\n",
      "Epoch 67 | Training Loss: 86.58 | Validation Loss: 740.29\n",
      "Epoch 68 | Training Loss: 133.55 | Validation Loss: 886.66\n",
      "Epoch 69 | Training Loss: 175.90 | Validation Loss: 728.65\n",
      "Epoch 70 | Training Loss: 180.05 | Validation Loss: 762.44\n",
      "Epoch 71 | Training Loss: 150.56 | Validation Loss: 800.15\n",
      "Epoch 72 | Training Loss: 122.24 | Validation Loss: 796.27\n",
      "Epoch 73 | Training Loss: 142.60 | Validation Loss: 743.60\n",
      "Epoch 74 | Training Loss: 155.26 | Validation Loss: 745.24\n",
      "Epoch 75 | Training Loss: 102.77 | Validation Loss: 730.41\n",
      "Epoch 76 | Training Loss: 90.91 | Validation Loss: 686.39\n",
      "Epoch 77 | Training Loss: 83.57 | Validation Loss: 670.41\n",
      "Epoch 78 | Training Loss: 70.30 | Validation Loss: 756.04\n",
      "Epoch 79 | Training Loss: 101.23 | Validation Loss: 763.87\n",
      "Epoch 80 | Training Loss: 176.17 | Validation Loss: 790.16\n",
      "Epoch 81 | Training Loss: 172.54 | Validation Loss: 775.97\n",
      "Epoch 82 | Training Loss: 147.85 | Validation Loss: 759.89\n",
      "Epoch 83 | Training Loss: 97.86 | Validation Loss: 784.05\n",
      "Epoch 84 | Training Loss: 139.80 | Validation Loss: 737.06\n",
      "Epoch 85 | Training Loss: 181.08 | Validation Loss: 823.74\n",
      "Epoch 86 | Training Loss: 168.35 | Validation Loss: 802.28\n",
      "Epoch 87 | Training Loss: 76.83 | Validation Loss: 749.23\n",
      "Epoch 88 | Training Loss: 57.21 | Validation Loss: 703.95\n",
      "Epoch 89 | Training Loss: 65.23 | Validation Loss: 759.03\n",
      "Epoch 90 | Training Loss: 68.13 | Validation Loss: 776.09\n",
      "Epoch 91 | Training Loss: 66.16 | Validation Loss: 688.68\n",
      "Epoch 92 | Training Loss: 172.71 | Validation Loss: 844.12\n",
      "Epoch 93 | Training Loss: 115.20 | Validation Loss: 745.69\n",
      "Epoch 94 | Training Loss: 114.99 | Validation Loss: 720.05\n",
      "Epoch 95 | Training Loss: 99.16 | Validation Loss: 716.19\n",
      "Epoch 96 | Training Loss: 85.50 | Validation Loss: 814.82\n",
      "Epoch 97 | Training Loss: 158.79 | Validation Loss: 756.58\n",
      "Epoch 98 | Training Loss: 152.27 | Validation Loss: 771.01\n",
      "Epoch 99 | Training Loss: 86.41 | Validation Loss: 792.36\n",
      "Epoch 100 | Training Loss: 54.18 | Validation Loss: 727.37\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    batch_train_losses = []\n",
    "    for batch in train_loader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x_batch).squeeze()\n",
    "        loss = loss_fn(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_train_losses.append(loss.item())\n",
    "\n",
    "    avg_train_loss = np.mean(batch_train_losses)\n",
    "    mlp_train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    batch_val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_batch, y_batch = batch\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            predictions = model(x_batch).squeeze()\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            batch_val_losses.append(loss.item())\n",
    "\n",
    "    avg_val_loss = np.mean(batch_val_losses)\n",
    "    mlp_val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} | Training Loss: {avg_train_loss:.2f} | Validation Loss: {avg_val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Convert training and validation sets to DMatrix format\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Convert training and validation sets to DMatrix format\n",
    "xgb_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xgb_val = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Parameters for XGBoost\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation metrics for each round\n",
    "xgb_eval_result = {}\n",
    "\n",
    "# Train XGBoost model with evaluation at each round\n",
    "xgb_model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=xgb_train,\n",
    "    num_boost_round=100,  # Set number of boosting rounds, similar to epochs\n",
    "    evals=[(xgb_train, \"train\"), (xgb_val, \"validation\")],\n",
    "    evals_result=xgb_eval_result,\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "# Extract training and validation losses (RMSE) for each boosting round\n",
    "xgb_train_losses = xgb_eval_result[\"train\"][\"rmse\"]\n",
    "xgb_val_losses = xgb_eval_result[\"validation\"][\"rmse\"]\n",
    "\n",
    "for i, (train_loss, val_loss) in enumerate(zip(xgb_train_losses, xgb_val_losses), start=1):\n",
    "    print(f\"Boosting Round {i} | Training RMSE: {train_loss:.2f} | Validation RMSE: {val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust epochs to match the minimum length available across all lists\n",
    "epochs = range(1, min(len(mlp_train_losses), len(xgb_train_losses)) + 1)\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# MLP Loss Plot\n",
    "ax1.plot(epochs, mlp_train_losses[:len(epochs)], label=\"MLP Training Loss (MSE)\", marker='o')\n",
    "ax1.plot(epochs, mlp_val_losses[:len(epochs)], label=\"MLP Validation Loss (MSE)\", marker='o')\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss (MSE)\")\n",
    "ax1.set_title(\"MLP Training and Validation Loss\")\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# XGBoost Loss Plot\n",
    "ax2.plot(epochs, xgb_train_losses[:len(epochs)], label=\"XGBoost Training Loss (RMSE)\", marker='x')\n",
    "ax2.plot(epochs, xgb_val_losses[:len(epochs)], label=\"XGBoost Validation Loss (RMSE)\", marker='x')\n",
    "ax2.set_xlabel(\"Boosting Round\")\n",
    "ax2.set_ylabel(\"Loss (RMSE)\")\n",
    "ax2.set_title(\"XGBoost Training and Validation Loss\")\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Show the combined figure\n",
    "plt.suptitle(\"Training and Validation Loss Comparison: MLP vs XGBoost\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import graphviz\n",
    "\n",
    "# Assuming `xgb_model` is the trained XGBoost model\n",
    "# Export the first tree in Graphviz format\n",
    "xgboost_tree = xgb.to_graphviz(xgb_model, num_trees=0)\n",
    "\n",
    "# Save as PDF for high resolution\n",
    "xgboost_tree.render(filename=\"xgboost_tree_visualization\", format=\"png\")\n",
    "\n",
    "# Alternatively, you can save as PNG, but PDF will retain the best quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `xgb_model` is the trained XGBoost model\n",
    "\n",
    "# Create a high-resolution figure\n",
    "plt.figure(figsize=(40, 30), dpi=1000)  # Increase `figsize` and `dpi` for better resolution\n",
    "plot_tree(xgb_model, num_trees=0, rankdir='LR')\n",
    "plt.title(\"Visualization of Boosted Tree (XGBoost)\")\n",
    "\n",
    "# Save the plot to the working directory as a high-resolution PNG\n",
    "plt.savefig(\"xgboost_tree_visualization.png\", format='png', bbox_inches='tight')\n",
    "\n",
    "# Display the plot in the notebook\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "from IPython.display import Image\n",
    "\n",
    "# Generate a sample input tensor\n",
    "sample_input = torch.randn(1, features.shape[1])  # Replace `features.shape[1]` with the actual input size\n",
    "\n",
    "# Perform a forward pass to create the computation graph\n",
    "output = model(sample_input)\n",
    "\n",
    "# Generate and render the MLP structure as an image\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot.format = 'png'\n",
    "dot.render(\"MLP_Structure\")  # This saves the image as \"MLP_Structure.png\"\n",
    "\n",
    "# Display the generated image in the notebook\n",
    "Image(filename=\"MLP_Structure.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3822067,
     "sourceId": 6655600,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
