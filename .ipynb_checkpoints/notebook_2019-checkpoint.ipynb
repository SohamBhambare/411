{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4542343, 30)\n",
      "(4542343, 30)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./archive/train.csv\")\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DEP_DEL15</th>\n",
       "      <th>DEP_TIME_BLK</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "      <th>SEGMENT_NUMBER</th>\n",
       "      <th>CONCURRENT_FLIGHTS</th>\n",
       "      <th>NUMBER_OF_SEATS</th>\n",
       "      <th>CARRIER_NAME</th>\n",
       "      <th>AIRPORT_FLIGHTS_MONTH</th>\n",
       "      <th>...</th>\n",
       "      <th>PREVIOUS_AIRPORT</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>AWND</th>\n",
       "      <th>CARRIER_HISTORICAL</th>\n",
       "      <th>DEP_AIRPORT_HIST</th>\n",
       "      <th>DAY_HISTORICAL</th>\n",
       "      <th>DEP_BLOCK_HIST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>160</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>19534</td>\n",
       "      <td>...</td>\n",
       "      <td>Chicago O'Hare International</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.237709</td>\n",
       "      <td>0.273236</td>\n",
       "      <td>0.222538</td>\n",
       "      <td>0.255479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1300-1359</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>50</td>\n",
       "      <td>SkyWest Airlines Inc.</td>\n",
       "      <td>18788</td>\n",
       "      <td>...</td>\n",
       "      <td>El Paso International</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>11.41</td>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.121849</td>\n",
       "      <td>0.237972</td>\n",
       "      <td>0.197503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0001-0559</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>American Eagle Airlines Inc.</td>\n",
       "      <td>1148</td>\n",
       "      <td>...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.117559</td>\n",
       "      <td>0.187867</td>\n",
       "      <td>0.139886</td>\n",
       "      <td>0.060327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>143</td>\n",
       "      <td>Southwest Airlines Co.</td>\n",
       "      <td>7612</td>\n",
       "      <td>...</td>\n",
       "      <td>San Jose International</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.204389</td>\n",
       "      <td>0.141446</td>\n",
       "      <td>0.132868</td>\n",
       "      <td>0.202037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0800-0859</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>American Eagle Airlines Inc.</td>\n",
       "      <td>29376</td>\n",
       "      <td>...</td>\n",
       "      <td>Cincinnati/Northern Kentucky International</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>10.51</td>\n",
       "      <td>0.203263</td>\n",
       "      <td>0.193761</td>\n",
       "      <td>0.203027</td>\n",
       "      <td>0.113050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0800-0859</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>11294</td>\n",
       "      <td>...</td>\n",
       "      <td>Logan International</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.174758</td>\n",
       "      <td>0.144157</td>\n",
       "      <td>0.167321</td>\n",
       "      <td>0.084255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0700-0759</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>150</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>6491</td>\n",
       "      <td>...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>11.18</td>\n",
       "      <td>0.142302</td>\n",
       "      <td>0.187867</td>\n",
       "      <td>0.147498</td>\n",
       "      <td>0.076535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-1959</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>154</td>\n",
       "      <td>United Air Lines Inc.</td>\n",
       "      <td>23099</td>\n",
       "      <td>...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0.221460</td>\n",
       "      <td>0.187867</td>\n",
       "      <td>0.161870</td>\n",
       "      <td>0.322358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0800-0859</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>173</td>\n",
       "      <td>United Air Lines Inc.</td>\n",
       "      <td>19667</td>\n",
       "      <td>...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.236601</td>\n",
       "      <td>0.187867</td>\n",
       "      <td>0.203027</td>\n",
       "      <td>0.113050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-2059</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>4275</td>\n",
       "      <td>...</td>\n",
       "      <td>Philadelphia International</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0.237709</td>\n",
       "      <td>0.243625</td>\n",
       "      <td>0.202012</td>\n",
       "      <td>0.336198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY_OF_WEEK  DEP_DEL15 DEP_TIME_BLK  DISTANCE_GROUP  SEGMENT_NUMBER  \\\n",
       "0      7            7          0    1500-1559               3               3   \n",
       "1      4            1          0    1300-1359               4               4   \n",
       "2     11            4          0    0001-0559               2               1   \n",
       "3      3            2          0    1500-1559               7               5   \n",
       "4      7            3          0    0800-0859               1               2   \n",
       "5      9            4          0    0800-0859               2               2   \n",
       "6     11            3          0    0700-0759               8               1   \n",
       "7      8            6          1    1900-1959               3               1   \n",
       "8      7            3          0    0800-0859              11               1   \n",
       "9      7            2          1    2000-2059               1               6   \n",
       "\n",
       "   CONCURRENT_FLIGHTS  NUMBER_OF_SEATS                  CARRIER_NAME  \\\n",
       "0                  26              160        American Airlines Inc.   \n",
       "1                  63               50         SkyWest Airlines Inc.   \n",
       "2                   3               76  American Eagle Airlines Inc.   \n",
       "3                  14              143        Southwest Airlines Co.   \n",
       "4                  85               50  American Eagle Airlines Inc.   \n",
       "5                  32              100               JetBlue Airways   \n",
       "6                  18              150        American Airlines Inc.   \n",
       "7                  39              154         United Air Lines Inc.   \n",
       "8                  48              173         United Air Lines Inc.   \n",
       "9                   3               99        American Airlines Inc.   \n",
       "\n",
       "   AIRPORT_FLIGHTS_MONTH  ...                            PREVIOUS_AIRPORT  \\\n",
       "0                  19534  ...                Chicago O'Hare International   \n",
       "1                  18788  ...                       El Paso International   \n",
       "2                   1148  ...                                        NONE   \n",
       "3                   7612  ...                      San Jose International   \n",
       "4                  29376  ...  Cincinnati/Northern Kentucky International   \n",
       "5                  11294  ...                         Logan International   \n",
       "6                   6491  ...                                        NONE   \n",
       "7                  23099  ...                                        NONE   \n",
       "8                  19667  ...                                        NONE   \n",
       "9                   4275  ...                  Philadelphia International   \n",
       "\n",
       "   PRCP  SNOW  SNWD  TMAX   AWND  CARRIER_HISTORICAL DEP_AIRPORT_HIST  \\\n",
       "0  0.00   0.0   0.0  95.0   4.25            0.237709         0.273236   \n",
       "1  0.00   0.0   0.0  71.0  11.41            0.154651         0.121849   \n",
       "2  0.00   0.0   0.0  54.0   0.45            0.117559         0.187867   \n",
       "3  0.00   0.0   0.0  64.0   8.05            0.204389         0.141446   \n",
       "4  0.01   0.0   0.0  94.0  10.51            0.203263         0.193761   \n",
       "5  0.01   0.0   0.0  89.0   3.80            0.174758         0.144157   \n",
       "6  0.00   0.0   0.0  69.0  11.18            0.142302         0.187867   \n",
       "7  0.00   0.0   0.0  84.0   8.95            0.221460         0.187867   \n",
       "8  0.00   0.0   0.0  72.0   8.05            0.236601         0.187867   \n",
       "9  0.68   0.0   0.0  89.0   8.95            0.237709         0.243625   \n",
       "\n",
       "   DAY_HISTORICAL  DEP_BLOCK_HIST  \n",
       "0        0.222538        0.255479  \n",
       "1        0.237972        0.197503  \n",
       "2        0.139886        0.060327  \n",
       "3        0.132868        0.202037  \n",
       "4        0.203027        0.113050  \n",
       "5        0.167321        0.084255  \n",
       "6        0.147498        0.076535  \n",
       "7        0.161870        0.322358  \n",
       "8        0.203027        0.113050  \n",
       "9        0.202012        0.336198  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./archive/train.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MONTH', 'DAY_OF_WEEK', 'DEP_DEL15', 'DEP_TIME_BLK', 'DISTANCE_GROUP',\n",
      "       'SEGMENT_NUMBER', 'CONCURRENT_FLIGHTS', 'NUMBER_OF_SEATS',\n",
      "       'CARRIER_NAME', 'AIRPORT_FLIGHTS_MONTH', 'AIRLINE_FLIGHTS_MONTH',\n",
      "       'AIRLINE_AIRPORT_FLIGHTS_MONTH', 'AVG_MONTHLY_PASS_AIRPORT',\n",
      "       'AVG_MONTHLY_PASS_AIRLINE', 'FLT_ATTENDANTS_PER_PASS',\n",
      "       'GROUND_SERV_PER_PASS', 'PLANE_AGE', 'DEPARTING_AIRPORT', 'LATITUDE',\n",
      "       'LONGITUDE', 'PREVIOUS_AIRPORT', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'AWND',\n",
      "       'CARRIER_HISTORICAL', 'DEP_AIRPORT_HIST', 'DAY_HISTORICAL',\n",
      "       'DEP_BLOCK_HIST'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude leaky variables -- we'll only keep what we think could reasonably be known before flight time\n",
    "features = ['MONTH', 'DAY_OF_WEEK', 'DISTANCE_GROUP',\n",
    "       'SEGMENT_NUMBER', 'CONCURRENT_FLIGHTS', 'NUMBER_OF_SEATS',\n",
    "       'CARRIER_NAME', 'AIRPORT_FLIGHTS_MONTH', 'AIRLINE_FLIGHTS_MONTH',\n",
    "       'AIRLINE_AIRPORT_FLIGHTS_MONTH', 'AVG_MONTHLY_PASS_AIRPORT',\n",
    "       'AVG_MONTHLY_PASS_AIRLINE', 'FLT_ATTENDANTS_PER_PASS',\n",
    "       'GROUND_SERV_PER_PASS', 'PLANE_AGE', 'DEPARTING_AIRPORT', 'LATITUDE',\n",
    "       'LONGITUDE', 'PREVIOUS_AIRPORT', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'AWND',\n",
    "       'CARRIER_HISTORICAL', 'DEP_AIRPORT_HIST', 'DAY_HISTORICAL',\n",
    "       'DEP_BLOCK_HIST']\n",
    "features = pd.get_dummies(df[features])\n",
    "labels = df['DEP_DEL15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "      <th>SEGMENT_NUMBER</th>\n",
       "      <th>CONCURRENT_FLIGHTS</th>\n",
       "      <th>NUMBER_OF_SEATS</th>\n",
       "      <th>AIRPORT_FLIGHTS_MONTH</th>\n",
       "      <th>AIRLINE_FLIGHTS_MONTH</th>\n",
       "      <th>AIRLINE_AIRPORT_FLIGHTS_MONTH</th>\n",
       "      <th>AVG_MONTHLY_PASS_AIRPORT</th>\n",
       "      <th>...</th>\n",
       "      <th>PREVIOUS_AIRPORT_William P Hobby</th>\n",
       "      <th>PREVIOUS_AIRPORT_Williams Gateway</th>\n",
       "      <th>PREVIOUS_AIRPORT_Williston Basin International</th>\n",
       "      <th>PREVIOUS_AIRPORT_Wilmington International</th>\n",
       "      <th>PREVIOUS_AIRPORT_Worcester Regional</th>\n",
       "      <th>PREVIOUS_AIRPORT_Yakutat Airport</th>\n",
       "      <th>PREVIOUS_AIRPORT_Yampa Valley</th>\n",
       "      <th>PREVIOUS_AIRPORT_Yellowstone</th>\n",
       "      <th>PREVIOUS_AIRPORT_Yellowstone Regional</th>\n",
       "      <th>PREVIOUS_AIRPORT_Yuma MCAS/Yuma International</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>160</td>\n",
       "      <td>19534</td>\n",
       "      <td>79247</td>\n",
       "      <td>7972</td>\n",
       "      <td>2006675</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>50</td>\n",
       "      <td>18788</td>\n",
       "      <td>67082</td>\n",
       "      <td>3655</td>\n",
       "      <td>2743323</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>1148</td>\n",
       "      <td>25517</td>\n",
       "      <td>300</td>\n",
       "      <td>90547</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>143</td>\n",
       "      <td>7612</td>\n",
       "      <td>114119</td>\n",
       "      <td>3282</td>\n",
       "      <td>1023434</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>29376</td>\n",
       "      <td>28267</td>\n",
       "      <td>6058</td>\n",
       "      <td>3103410</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY_OF_WEEK  DISTANCE_GROUP  SEGMENT_NUMBER  CONCURRENT_FLIGHTS  \\\n",
       "0      7            7               3               3                  26   \n",
       "1      4            1               4               4                  63   \n",
       "2     11            4               2               1                   3   \n",
       "3      3            2               7               5                  14   \n",
       "4      7            3               1               2                  85   \n",
       "\n",
       "   NUMBER_OF_SEATS  AIRPORT_FLIGHTS_MONTH  AIRLINE_FLIGHTS_MONTH  \\\n",
       "0              160                  19534                  79247   \n",
       "1               50                  18788                  67082   \n",
       "2               76                   1148                  25517   \n",
       "3              143                   7612                 114119   \n",
       "4               50                  29376                  28267   \n",
       "\n",
       "   AIRLINE_AIRPORT_FLIGHTS_MONTH  AVG_MONTHLY_PASS_AIRPORT  ...  \\\n",
       "0                           7972                   2006675  ...   \n",
       "1                           3655                   2743323  ...   \n",
       "2                            300                     90547  ...   \n",
       "3                           3282                   1023434  ...   \n",
       "4                           6058                   3103410  ...   \n",
       "\n",
       "   PREVIOUS_AIRPORT_William P Hobby  PREVIOUS_AIRPORT_Williams Gateway  \\\n",
       "0                             False                              False   \n",
       "1                             False                              False   \n",
       "2                             False                              False   \n",
       "3                             False                              False   \n",
       "4                             False                              False   \n",
       "\n",
       "   PREVIOUS_AIRPORT_Williston Basin International  \\\n",
       "0                                           False   \n",
       "1                                           False   \n",
       "2                                           False   \n",
       "3                                           False   \n",
       "4                                           False   \n",
       "\n",
       "   PREVIOUS_AIRPORT_Wilmington International  \\\n",
       "0                                      False   \n",
       "1                                      False   \n",
       "2                                      False   \n",
       "3                                      False   \n",
       "4                                      False   \n",
       "\n",
       "   PREVIOUS_AIRPORT_Worcester Regional  PREVIOUS_AIRPORT_Yakutat Airport  \\\n",
       "0                                False                             False   \n",
       "1                                False                             False   \n",
       "2                                False                             False   \n",
       "3                                False                             False   \n",
       "4                                False                             False   \n",
       "\n",
       "   PREVIOUS_AIRPORT_Yampa Valley  PREVIOUS_AIRPORT_Yellowstone  \\\n",
       "0                          False                         False   \n",
       "1                          False                         False   \n",
       "2                          False                         False   \n",
       "3                          False                         False   \n",
       "4                          False                         False   \n",
       "\n",
       "   PREVIOUS_AIRPORT_Yellowstone Regional  \\\n",
       "0                                  False   \n",
       "1                                  False   \n",
       "2                                  False   \n",
       "3                                  False   \n",
       "4                                  False   \n",
       "\n",
       "   PREVIOUS_AIRPORT_Yuma MCAS/Yuma International  \n",
       "0                                          False  \n",
       "1                                          False  \n",
       "2                                          False  \n",
       "3                                          False  \n",
       "4                                          False  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PyTorch Dataset\n",
    "class DelayDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.features.iloc[idx].values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels.iloc[idx], dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Datasets and DataLoaders\n",
    "train_dataset = DelayDataset(X_train, y_train)\n",
    "val_dataset = DelayDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel(input_size=features.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Define Loss and Optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with Validation\n",
    "epochs = 100\n",
    "mlp_train_losses, mlp_val_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Training Loss: 23716.93 | Validation Loss: 6360.14\n",
      "Epoch 2 | Training Loss: 13935.30 | Validation Loss: 5831.98\n",
      "Epoch 3 | Training Loss: 7699.56 | Validation Loss: 5079.62\n",
      "Epoch 4 | Training Loss: 4537.81 | Validation Loss: 5684.36\n",
      "Epoch 5 | Training Loss: 3495.87 | Validation Loss: 2206.79\n",
      "Epoch 6 | Training Loss: 2753.66 | Validation Loss: 2710.63\n",
      "Epoch 7 | Training Loss: 2390.81 | Validation Loss: 2129.98\n",
      "Epoch 8 | Training Loss: 2035.59 | Validation Loss: 1937.40\n",
      "Epoch 9 | Training Loss: 1817.28 | Validation Loss: 2023.33\n",
      "Epoch 10 | Training Loss: 1709.52 | Validation Loss: 1712.31\n",
      "Epoch 11 | Training Loss: 1462.84 | Validation Loss: 1641.12\n",
      "Epoch 12 | Training Loss: 1326.95 | Validation Loss: 1635.30\n",
      "Epoch 13 | Training Loss: 1209.44 | Validation Loss: 1615.79\n",
      "Epoch 14 | Training Loss: 1054.66 | Validation Loss: 1772.17\n",
      "Epoch 15 | Training Loss: 991.88 | Validation Loss: 1534.09\n",
      "Epoch 16 | Training Loss: 898.30 | Validation Loss: 1635.55\n",
      "Epoch 17 | Training Loss: 802.84 | Validation Loss: 1418.98\n",
      "Epoch 18 | Training Loss: 759.02 | Validation Loss: 1964.63\n",
      "Epoch 19 | Training Loss: 675.63 | Validation Loss: 1279.93\n",
      "Epoch 20 | Training Loss: 547.85 | Validation Loss: 1109.22\n",
      "Epoch 21 | Training Loss: 489.19 | Validation Loss: 1403.19\n",
      "Epoch 22 | Training Loss: 526.64 | Validation Loss: 1293.19\n",
      "Epoch 23 | Training Loss: 488.88 | Validation Loss: 1216.52\n",
      "Epoch 24 | Training Loss: 501.21 | Validation Loss: 1247.13\n",
      "Epoch 25 | Training Loss: 500.31 | Validation Loss: 1358.09\n",
      "Epoch 26 | Training Loss: 465.65 | Validation Loss: 1263.11\n",
      "Epoch 27 | Training Loss: 443.80 | Validation Loss: 1224.56\n",
      "Epoch 28 | Training Loss: 401.80 | Validation Loss: 1226.21\n",
      "Epoch 29 | Training Loss: 397.55 | Validation Loss: 1161.60\n",
      "Epoch 30 | Training Loss: 363.71 | Validation Loss: 1192.17\n",
      "Epoch 31 | Training Loss: 365.69 | Validation Loss: 1036.02\n",
      "Epoch 32 | Training Loss: 372.03 | Validation Loss: 1308.83\n",
      "Epoch 33 | Training Loss: 343.62 | Validation Loss: 1146.31\n",
      "Epoch 34 | Training Loss: 356.83 | Validation Loss: 1227.21\n",
      "Epoch 35 | Training Loss: 299.33 | Validation Loss: 1080.32\n",
      "Epoch 36 | Training Loss: 286.61 | Validation Loss: 1168.55\n",
      "Epoch 37 | Training Loss: 254.50 | Validation Loss: 1196.69\n",
      "Epoch 38 | Training Loss: 319.77 | Validation Loss: 1161.54\n",
      "Epoch 39 | Training Loss: 298.36 | Validation Loss: 1173.05\n",
      "Epoch 40 | Training Loss: 278.80 | Validation Loss: 1074.27\n",
      "Epoch 41 | Training Loss: 300.35 | Validation Loss: 1217.20\n",
      "Epoch 42 | Training Loss: 341.33 | Validation Loss: 1147.18\n",
      "Epoch 43 | Training Loss: 274.63 | Validation Loss: 1080.45\n",
      "Epoch 44 | Training Loss: 375.83 | Validation Loss: 1070.85\n",
      "Epoch 45 | Training Loss: 279.46 | Validation Loss: 1126.35\n",
      "Epoch 46 | Training Loss: 282.18 | Validation Loss: 1068.82\n",
      "Epoch 47 | Training Loss: 407.02 | Validation Loss: 1157.37\n",
      "Epoch 48 | Training Loss: 566.25 | Validation Loss: 1096.77\n",
      "Epoch 49 | Training Loss: 340.50 | Validation Loss: 1087.01\n",
      "Epoch 50 | Training Loss: 287.55 | Validation Loss: 1193.05\n",
      "Epoch 51 | Training Loss: 236.44 | Validation Loss: 1031.59\n",
      "Epoch 52 | Training Loss: 193.75 | Validation Loss: 1018.63\n",
      "Epoch 53 | Training Loss: 161.40 | Validation Loss: 983.13\n",
      "Epoch 54 | Training Loss: 150.75 | Validation Loss: 991.51\n",
      "Epoch 55 | Training Loss: 155.87 | Validation Loss: 999.87\n",
      "Epoch 56 | Training Loss: 169.68 | Validation Loss: 1011.25\n",
      "Epoch 57 | Training Loss: 284.96 | Validation Loss: 1019.07\n",
      "Epoch 58 | Training Loss: 199.98 | Validation Loss: 964.49\n",
      "Epoch 59 | Training Loss: 240.14 | Validation Loss: 958.76\n",
      "Epoch 60 | Training Loss: 164.40 | Validation Loss: 964.98\n",
      "Epoch 61 | Training Loss: 125.79 | Validation Loss: 977.65\n",
      "Epoch 62 | Training Loss: 139.45 | Validation Loss: 1015.84\n",
      "Epoch 63 | Training Loss: 149.53 | Validation Loss: 900.63\n",
      "Epoch 64 | Training Loss: 150.52 | Validation Loss: 937.91\n",
      "Epoch 65 | Training Loss: 256.46 | Validation Loss: 1226.75\n",
      "Epoch 66 | Training Loss: 223.71 | Validation Loss: 956.30\n",
      "Epoch 67 | Training Loss: 197.72 | Validation Loss: 957.84\n",
      "Epoch 68 | Training Loss: 218.05 | Validation Loss: 983.92\n",
      "Epoch 69 | Training Loss: 187.69 | Validation Loss: 1013.74\n",
      "Epoch 70 | Training Loss: 135.95 | Validation Loss: 986.28\n",
      "Epoch 71 | Training Loss: 147.26 | Validation Loss: 947.90\n",
      "Epoch 72 | Training Loss: 107.11 | Validation Loss: 913.23\n",
      "Epoch 73 | Training Loss: 76.41 | Validation Loss: 967.10\n",
      "Epoch 74 | Training Loss: 102.67 | Validation Loss: 974.74\n",
      "Epoch 75 | Training Loss: 90.90 | Validation Loss: 895.07\n",
      "Epoch 76 | Training Loss: 105.58 | Validation Loss: 1012.44\n",
      "Epoch 77 | Training Loss: 115.04 | Validation Loss: 1128.67\n",
      "Epoch 78 | Training Loss: 181.02 | Validation Loss: 867.02\n",
      "Epoch 79 | Training Loss: 150.17 | Validation Loss: 1012.97\n",
      "Epoch 80 | Training Loss: 151.00 | Validation Loss: 875.45\n",
      "Epoch 81 | Training Loss: 143.17 | Validation Loss: 888.52\n",
      "Epoch 82 | Training Loss: 113.38 | Validation Loss: 946.26\n",
      "Epoch 83 | Training Loss: 86.18 | Validation Loss: 901.02\n",
      "Epoch 84 | Training Loss: 78.60 | Validation Loss: 838.51\n",
      "Epoch 85 | Training Loss: 64.81 | Validation Loss: 872.47\n",
      "Epoch 86 | Training Loss: 88.75 | Validation Loss: 900.19\n",
      "Epoch 87 | Training Loss: 93.70 | Validation Loss: 838.00\n",
      "Epoch 88 | Training Loss: 108.38 | Validation Loss: 1072.45\n",
      "Epoch 89 | Training Loss: 145.07 | Validation Loss: 1001.65\n",
      "Epoch 90 | Training Loss: 147.54 | Validation Loss: 891.42\n",
      "Epoch 91 | Training Loss: 190.32 | Validation Loss: 895.20\n",
      "Epoch 92 | Training Loss: 174.98 | Validation Loss: 958.87\n",
      "Epoch 93 | Training Loss: 82.49 | Validation Loss: 879.56\n",
      "Epoch 94 | Training Loss: 65.89 | Validation Loss: 921.99\n",
      "Epoch 95 | Training Loss: 58.57 | Validation Loss: 909.99\n",
      "Epoch 96 | Training Loss: 54.18 | Validation Loss: 1005.19\n",
      "Epoch 97 | Training Loss: 55.42 | Validation Loss: 891.84\n",
      "Epoch 98 | Training Loss: 77.57 | Validation Loss: 1019.15\n",
      "Epoch 99 | Training Loss: 82.73 | Validation Loss: 875.07\n",
      "Epoch 100 | Training Loss: 107.55 | Validation Loss: 1090.13\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    batch_train_losses = []\n",
    "    for batch in train_loader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x_batch).squeeze()\n",
    "        loss = loss_fn(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_train_losses.append(loss.item())\n",
    "\n",
    "    avg_train_loss = np.mean(batch_train_losses)\n",
    "    mlp_train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    batch_val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_batch, y_batch = batch\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            predictions = model(x_batch).squeeze()\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            batch_val_losses.append(loss.item())\n",
    "\n",
    "    avg_val_loss = np.mean(batch_val_losses)\n",
    "    mlp_val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} | Training Loss: {avg_train_loss:.2f} | Validation Loss: {avg_val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Convert training and validation sets to DMatrix format\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Convert training and validation sets to DMatrix format\n",
    "xgb_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xgb_val = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Parameters for XGBoost\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation metrics for each round\n",
    "xgb_eval_result = {}\n",
    "\n",
    "# Train XGBoost model with evaluation at each round\n",
    "xgb_model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=xgb_train,\n",
    "    num_boost_round=100,  # Set number of boosting rounds, similar to epochs\n",
    "    evals=[(xgb_train, \"train\"), (xgb_val, \"validation\")],\n",
    "    evals_result=xgb_eval_result,\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "# Extract training and validation losses (RMSE) for each boosting round\n",
    "xgb_train_losses = xgb_eval_result[\"train\"][\"rmse\"]\n",
    "xgb_val_losses = xgb_eval_result[\"validation\"][\"rmse\"]\n",
    "\n",
    "for i, (train_loss, val_loss) in enumerate(zip(xgb_train_losses, xgb_val_losses), start=1):\n",
    "    print(f\"Boosting Round {i} | Training RMSE: {train_loss:.2f} | Validation RMSE: {val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust epochs to match the minimum length available across all lists\n",
    "epochs = range(1, min(len(mlp_train_losses), len(xgb_train_losses)) + 1)\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# MLP Loss Plot\n",
    "ax1.plot(epochs, mlp_train_losses[:len(epochs)], label=\"MLP Training Loss (MSE)\", marker='o')\n",
    "ax1.plot(epochs, mlp_val_losses[:len(epochs)], label=\"MLP Validation Loss (MSE)\", marker='o')\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss (MSE)\")\n",
    "ax1.set_title(\"MLP Training and Validation Loss\")\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# XGBoost Loss Plot\n",
    "ax2.plot(epochs, xgb_train_losses[:len(epochs)], label=\"XGBoost Training Loss (RMSE)\", marker='x')\n",
    "ax2.plot(epochs, xgb_val_losses[:len(epochs)], label=\"XGBoost Validation Loss (RMSE)\", marker='x')\n",
    "ax2.set_xlabel(\"Boosting Round\")\n",
    "ax2.set_ylabel(\"Loss (RMSE)\")\n",
    "ax2.set_title(\"XGBoost Training and Validation Loss\")\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Show the combined figure\n",
    "plt.suptitle(\"Training and Validation Loss Comparison: MLP vs XGBoost\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import graphviz\n",
    "\n",
    "# Assuming `xgb_model` is the trained XGBoost model\n",
    "# Export the first tree in Graphviz format\n",
    "xgboost_tree = xgb.to_graphviz(xgb_model, num_trees=0)\n",
    "\n",
    "# Save as PDF for high resolution\n",
    "xgboost_tree.render(filename=\"xgboost_tree_visualization\", format=\"png\")\n",
    "\n",
    "# Alternatively, you can save as PNG, but PDF will retain the best quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `xgb_model` is the trained XGBoost model\n",
    "\n",
    "# Create a high-resolution figure\n",
    "plt.figure(figsize=(40, 30), dpi=1000)  # Increase `figsize` and `dpi` for better resolution\n",
    "plot_tree(xgb_model, num_trees=0, rankdir='LR')\n",
    "plt.title(\"Visualization of Boosted Tree (XGBoost)\")\n",
    "\n",
    "# Save the plot to the working directory as a high-resolution PNG\n",
    "plt.savefig(\"xgboost_tree_visualization.png\", format='png', bbox_inches='tight')\n",
    "\n",
    "# Display the plot in the notebook\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "from IPython.display import Image\n",
    "\n",
    "# Generate a sample input tensor\n",
    "sample_input = torch.randn(1, features.shape[1])  # Replace `features.shape[1]` with the actual input size\n",
    "\n",
    "# Perform a forward pass to create the computation graph\n",
    "output = model(sample_input)\n",
    "\n",
    "# Generate and render the MLP structure as an image\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot.format = 'png'\n",
    "dot.render(\"MLP_Structure\")  # This saves the image as \"MLP_Structure.png\"\n",
    "\n",
    "# Display the generated image in the notebook\n",
    "Image(filename=\"MLP_Structure.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3822067,
     "sourceId": 6655600,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
